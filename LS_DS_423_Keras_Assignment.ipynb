{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (404, 13)\n",
      "y_train shape: (404,)\n",
      "x_test shape: (102, 13)\n",
      "y_test shape: (102,)\n"
     ]
    }
   ],
   "source": [
    "#Taking a look at the data\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepping the data\n",
    "mean = x_train.mean(axis = 0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis = 0)\n",
    "x_train /= std\n",
    "\n",
    "#Normalizing x_test\n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 15:58:42.455029 140735563645760 deprecation.py:506] From /Users/danielcalimayor/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "boston_model = Sequential()\n",
    "\n",
    "#Input\n",
    "boston_model.add(Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "#Hidden\n",
    "boston_model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "boston_model.add(Dense(1))\n",
    "\n",
    "#compile\n",
    "boston_model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 2s 6ms/sample - loss: 492.2014 - mean_absolute_error: 20.3530 - val_loss: 517.6126 - val_mean_absolute_error: 20.4512\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 340us/sample - loss: 361.7618 - mean_absolute_error: 16.9148 - val_loss: 339.4612 - val_mean_absolute_error: 15.8010\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 398us/sample - loss: 179.0446 - mean_absolute_error: 10.9466 - val_loss: 150.6163 - val_mean_absolute_error: 9.1991\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 398us/sample - loss: 69.4672 - mean_absolute_error: 6.3382 - val_loss: 88.8301 - val_mean_absolute_error: 6.9112\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 381us/sample - loss: 41.3196 - mean_absolute_error: 4.6732 - val_loss: 64.0340 - val_mean_absolute_error: 5.4138\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 411us/sample - loss: 28.7783 - mean_absolute_error: 3.8263 - val_loss: 48.8798 - val_mean_absolute_error: 4.5855\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 368us/sample - loss: 22.5229 - mean_absolute_error: 3.4033 - val_loss: 41.6552 - val_mean_absolute_error: 4.1650\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 353us/sample - loss: 19.4448 - mean_absolute_error: 3.1113 - val_loss: 38.2776 - val_mean_absolute_error: 3.8964\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 311us/sample - loss: 17.7140 - mean_absolute_error: 2.9515 - val_loss: 33.9759 - val_mean_absolute_error: 3.7226\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 335us/sample - loss: 16.0447 - mean_absolute_error: 2.8111 - val_loss: 31.4464 - val_mean_absolute_error: 3.5907\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 407us/sample - loss: 14.9737 - mean_absolute_error: 2.7073 - val_loss: 29.0180 - val_mean_absolute_error: 3.4655\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 322us/sample - loss: 13.9659 - mean_absolute_error: 2.6311 - val_loss: 26.9931 - val_mean_absolute_error: 3.3529\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 348us/sample - loss: 13.0797 - mean_absolute_error: 2.5570 - val_loss: 26.1775 - val_mean_absolute_error: 3.2720\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 309us/sample - loss: 12.4229 - mean_absolute_error: 2.5054 - val_loss: 24.6177 - val_mean_absolute_error: 3.2014\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 326us/sample - loss: 11.7164 - mean_absolute_error: 2.4523 - val_loss: 23.8019 - val_mean_absolute_error: 3.1386\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 323us/sample - loss: 11.4032 - mean_absolute_error: 2.4076 - val_loss: 22.4750 - val_mean_absolute_error: 3.0468\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 324us/sample - loss: 10.7324 - mean_absolute_error: 2.3400 - val_loss: 22.2320 - val_mean_absolute_error: 3.0212\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 340us/sample - loss: 10.3744 - mean_absolute_error: 2.3203 - val_loss: 21.2382 - val_mean_absolute_error: 2.9978\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 550us/sample - loss: 9.9992 - mean_absolute_error: 2.2992 - val_loss: 20.4825 - val_mean_absolute_error: 2.9098\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 829us/sample - loss: 9.4053 - mean_absolute_error: 2.2360 - val_loss: 20.5146 - val_mean_absolute_error: 2.9479\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 377us/sample - loss: 9.2449 - mean_absolute_error: 2.2123 - val_loss: 19.7591 - val_mean_absolute_error: 2.8999\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 344us/sample - loss: 8.7644 - mean_absolute_error: 2.1669 - val_loss: 19.0744 - val_mean_absolute_error: 2.8350\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 851us/sample - loss: 8.5991 - mean_absolute_error: 2.1391 - val_loss: 19.0113 - val_mean_absolute_error: 2.8764\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 513us/sample - loss: 8.3447 - mean_absolute_error: 2.1530 - val_loss: 18.4160 - val_mean_absolute_error: 2.7967\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 736us/sample - loss: 8.1584 - mean_absolute_error: 2.0829 - val_loss: 18.1698 - val_mean_absolute_error: 2.7799\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 344us/sample - loss: 7.9917 - mean_absolute_error: 2.1310 - val_loss: 18.2234 - val_mean_absolute_error: 2.8252\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 562us/sample - loss: 7.8708 - mean_absolute_error: 2.0212 - val_loss: 17.9046 - val_mean_absolute_error: 2.8033\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 658us/sample - loss: 7.4798 - mean_absolute_error: 2.0425 - val_loss: 17.5677 - val_mean_absolute_error: 2.7396\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 315us/sample - loss: 7.4134 - mean_absolute_error: 2.0054 - val_loss: 17.2649 - val_mean_absolute_error: 2.7294\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 329us/sample - loss: 7.2566 - mean_absolute_error: 1.9862 - val_loss: 17.4627 - val_mean_absolute_error: 2.7570\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 303us/sample - loss: 7.1875 - mean_absolute_error: 1.9447 - val_loss: 17.1247 - val_mean_absolute_error: 2.7339\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 318us/sample - loss: 7.0903 - mean_absolute_error: 1.9640 - val_loss: 16.9358 - val_mean_absolute_error: 2.7169\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 422us/sample - loss: 6.9818 - mean_absolute_error: 2.0004 - val_loss: 17.4690 - val_mean_absolute_error: 2.7465\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 775us/sample - loss: 6.8646 - mean_absolute_error: 1.8940 - val_loss: 16.9823 - val_mean_absolute_error: 2.7059\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 673us/sample - loss: 7.0644 - mean_absolute_error: 1.9625 - val_loss: 17.1671 - val_mean_absolute_error: 2.7124\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 651us/sample - loss: 6.7518 - mean_absolute_error: 1.9261 - val_loss: 17.0545 - val_mean_absolute_error: 2.7178\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 395us/sample - loss: 6.7395 - mean_absolute_error: 1.9065 - val_loss: 16.6478 - val_mean_absolute_error: 2.6821\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 323us/sample - loss: 6.5767 - mean_absolute_error: 1.9003 - val_loss: 16.7734 - val_mean_absolute_error: 2.7045\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 318us/sample - loss: 6.3861 - mean_absolute_error: 1.8714 - val_loss: 16.4466 - val_mean_absolute_error: 2.6322\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 522us/sample - loss: 6.2661 - mean_absolute_error: 1.8297 - val_loss: 16.6726 - val_mean_absolute_error: 2.6659\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 660us/sample - loss: 6.3774 - mean_absolute_error: 1.8364 - val_loss: 16.4537 - val_mean_absolute_error: 2.6140\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 616us/sample - loss: 6.2519 - mean_absolute_error: 1.8857 - val_loss: 16.5698 - val_mean_absolute_error: 2.6738\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 492us/sample - loss: 6.1710 - mean_absolute_error: 1.8160 - val_loss: 16.5175 - val_mean_absolute_error: 2.6671\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 406us/sample - loss: 6.0390 - mean_absolute_error: 1.7981 - val_loss: 16.3996 - val_mean_absolute_error: 2.6359\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 323us/sample - loss: 5.9418 - mean_absolute_error: 1.7923 - val_loss: 16.4894 - val_mean_absolute_error: 2.6559\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 365us/sample - loss: 5.8674 - mean_absolute_error: 1.7852 - val_loss: 16.1664 - val_mean_absolute_error: 2.5938\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 311us/sample - loss: 5.9413 - mean_absolute_error: 1.8027 - val_loss: 16.1268 - val_mean_absolute_error: 2.6108\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 322us/sample - loss: 5.9197 - mean_absolute_error: 1.7831 - val_loss: 16.4944 - val_mean_absolute_error: 2.6580\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 327us/sample - loss: 5.9593 - mean_absolute_error: 1.7738 - val_loss: 16.1579 - val_mean_absolute_error: 2.6020\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 317us/sample - loss: 5.6449 - mean_absolute_error: 1.7420 - val_loss: 16.2658 - val_mean_absolute_error: 2.6247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149478fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_model.fit(x_train, y_train, batch_size = 10, epochs = 50, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "#import\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#Hyperparameters\n",
    "batch_size = 64\n",
    "num_class = 10\n",
    "epochs = 20\n",
    "\n",
    "#Load Data\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "#Variable Type\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "#Correct encoding on Y\n",
    "# what softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_class)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "mnist_model = models.Sequential()\n",
    "\n",
    "# Hidden\n",
    "mnist_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "mnist_model.add(layers.MaxPooling2D((2, 2)))\n",
    "mnist_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "mnist_model.add(layers.MaxPooling2D((2, 2)))\n",
    "mnist_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Output Layer\n",
    "mnist_model.add(layers.Flatten())\n",
    "mnist_model.add(layers.Dense(64, activation='relu'))\n",
    "mnist_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "mnist_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='rmsprop', \n",
    "                    metrics=['accuracy'])\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0815 16:31:21.914704 140735563645760 deprecation.py:323] From /Users/danielcalimayor/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0815 16:31:22.072299 140735563645760 deprecation_wrapper.py:119] From /Users/danielcalimayor/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 44s 736us/step - loss: 0.1739 - acc: 0.9456\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 41s 686us/step - loss: 0.0469 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 41s 686us/step - loss: 0.0318 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 41s 688us/step - loss: 0.0240 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 46s 767us/step - loss: 0.0182 - acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1744e1ad0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.fit(X_train,Y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 341us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9909"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = mnist_model.evaluate(X_test, Y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "danlol",
   "language": "python",
   "name": "danlol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
